import os
import cv2
import glob
import numpy as np
import pandas as pd  # D√πng ƒë·ªÉ hi·ªÉn th·ªã b·∫£ng th·ªëng k√™ d·ªØ li·ªáu cho ƒë·∫πp
from src.preprocessing import remove_background
from src.features import extract_features
from src.models import AnomalyDetector, DefectClassifier
from src.augmentation import augment_image # <--- [NEW] Import module m·ªõi
from src import config

# ... (Gi·ªØ nguy√™n h√†m load_images_and_extract_features c≈© n·∫øu mu·ªën, ho·∫∑c d√πng logic m·ªõi d∆∞·ªõi ƒë√¢y)

def process_single_image(img):
    """H√†m ph·ª• tr·ª£: X·ª≠ l√Ω 1 ·∫£nh -> Tr·∫£ v·ªÅ feature vector"""
    processed_img, mask = remove_background(img)
    try:
        # extract_features c·∫ßn mask ƒë·ªÉ lo·∫°i b·ªè n·ªÅn ƒëen
        return extract_features(processed_img, mask)
    except:
        return None

def main():
    # ==========================================
    # GIAI ƒêO·∫†N 1: HU·∫§N LUY·ªÜN ONE-CLASS SVM (GI·ªÆ NGUY√äN)
    # ==========================================
    print("\n=== STAGE 1: TRAINING ANOMALY DETECTOR ===")
    train_good_path = os.path.join(config.DATA_PATH, "train", "good")
    image_paths = glob.glob(os.path.join(train_good_path, "*.png"))
    
    X_good = []
    print(f"Loading {len(image_paths)} good images for SVM...")
    
    for path in image_paths:
        img = cv2.imread(path)
        if img is None: continue
        feat = process_single_image(img)
        if feat is not None:
            X_good.append(feat)
            
    if X_good:
        # L∆∞u √Ω: Nh·ªõ ch·ªânh nu=0.2 trong src/models.py nh∆∞ ƒë√£ b√†n ·ªü b∆∞·ªõc tr∆∞·ªõc
        svm_model = AnomalyDetector()
        svm_model.train(X_good) 
        svm_model.save("anomaly_detector.pkl")
    else:
        print("‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu train/good")

    # ==========================================
    # GIAI ƒêO·∫†N 2: HU·∫§N LUY·ªÜN RANDOM FOREST (C√ì AUGMENTATION)
    # ==========================================
    print("\n=== STAGE 2: TRAINING DEFECT CLASSIFIER WITH AUGMENTATION ===")
    
    defect_types = ['crack', 'cut', 'hole', 'print']
    X_defects = []
    y_defects = []
    
    test_root_path = os.path.join(config.DATA_PATH, "test")
    
    # B·∫£ng th·ªëng k√™ ƒë·ªÉ ƒë∆∞a v√†o b√°o c√°o
    stats = []

    for idx, defect_name in enumerate(defect_types):
        folder_path = os.path.join(test_root_path, defect_name)
        if not os.path.exists(folder_path): continue
            
        img_paths = glob.glob(os.path.join(folder_path, "*.png"))
        original_count = len(img_paths)
        
        print(f"Processing '{defect_name}': {original_count} images found...")
        
        for path in img_paths:
            img = cv2.imread(path)
            if img is None: continue
            
            # --- [NEW] B∆Ø·ªöC NH√ÇN B·∫¢N D·ªÆ LI·ªÜU ---
            # T·∫°o ra 6 bi·∫øn th·ªÉ t·ª´ 1 ·∫£nh g·ªëc
            aug_imgs = augment_image(img)
            
            # Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng cho c·∫£ 6 ·∫£nh n√†y
            for aug_img in aug_imgs:
                feat = process_single_image(aug_img)
                if feat is not None:
                    X_defects.append(feat)
                    y_defects.append(idx)
        
        # Ghi l·∫°i th·ªëng k√™
        final_count = original_count * 6
        stats.append({
            "Lo·∫°i l·ªói": defect_name, 
            "S·ªë l∆∞·ª£ng g·ªëc": original_count, 
            "Sau Augmentation": final_count
        })

    # In b·∫£ng th·ªëng k√™ ra m√†n h√¨nh (Copy b·∫£ng n√†y v√†o b√°o c√°o r·∫•t ƒë·∫πp)
    print("\nüìä B·∫¢NG TH·ªêNG K√ä D·ªÆ LI·ªÜU SAU KHI NH√ÇN B·∫¢N:")
    df_stats = pd.DataFrame(stats)
    print(df_stats)
    print(f"\nT·ªïng c·ªông m·∫´u ƒë·ªÉ train Random Forest: {len(X_defects)}")

    if X_defects:
        rf_model = DefectClassifier()
        rf_model.train(X_defects, y_defects)
        rf_model.save("defect_classifier.pkl")
    else:
        print("‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu l·ªói (defect)!")

if __name__ == "__main__":
    main()